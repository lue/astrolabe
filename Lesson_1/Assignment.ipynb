{
 "metadata": {
  "name": "",
  "signature": "sha256:22f8be2ef8cb21b36532d4eba248adc7a291ac37e7e849057091ed2678b84fbd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assignment #1\n",
      "=============\n",
      "\n",
      "The objective of this assignment is to continue the analysis we have started doing in the lesson. If in the lesson the source code was already provided and you only ran it, now you are supposed to write it by yourself. However, steps you need to take are outlined and web links to various tutorials and library documentations are given for your own investigation.\n",
      "\n",
      "In this first assignment you will try to run the code from the very beginning (importing libraries and reading the data). Then you will explore how to make plots with errorbars. Finally, you will use the errors you have determined in order to do fitting. You are encouraged to use routines for fitting included in the libraries, however you can write your own (it is a great exercise, but do it only if you are confident in your abilities). \n",
      "\n",
      "Uncertainties of measurements\n",
      "-----------------------------\n",
      "\n",
      "The uncertainty consists of two components. The first is the measurement error and the second is intrinsic scatter. For instance, imagine an experiment where you measure the length of carrots with a ruler. Your ruler has some precision, say $0.1\\,\\rm{cm}$, in this case your measurement error will be $0.05\\,\\rm{cm}$. So the measurement of each carrot has an error $0.05,\\rm{cm}$. The average is, for instance, $10\\,\\rm{cm}$. But carrots are not the same length, therefore you have another source of uncertainty. Let's assume that that scatter in length is about $5\\,\\rm{cm}$. In this case the scatter dominates, and if now, after the experiment is complete, somebody will give you a carrot, you can say without any measurement that its length is $10 \\pm 5\\,\\rm{cm}$.\n",
      "\n",
      "Here we have two dimensional data. The magnitude of the source (expressed as distance moduli) and the redshift. \n",
      "\n",
      "Firstly, let's figure out what is an error in a redshift. \n",
      "\n",
      "The spectral analysis is able to extract the redshift of the source with very high precision. Therefore, the errors in the redshift are not given in the tables. However, the redshift we measure reveals only relative velocity to us, the observer. This velocity includes not only Hubble expansion, but also peculiar velocity of the source. This velocity can be estimated as a few hundreds of $\\rm{km/s}$. Therefore, this factor dominates and only its contribution to the uncertainty is considered.\n",
      "\n",
      "Secondly, the distance moduli. Situation is opposite to what we have with the redshift. Here the error in a measurement dominates the intrinsic scatter. This is mostly because we do not have much information about explosions.\n",
      "\n",
      "Thats said, now you should try to make a plot we have already done in the lesson but including the errors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import all necessary modules\n",
      "\n",
      "\n",
      "# and press Shift+Enter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# download and read the data (also convert redshifts to velocities)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make the same plot we had in the lesson\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we want to plot the errorbars on top of it. Let's do some preparations. Create two arrays, which will corresponds to the errors in velocities and distance moduli. Assign to the latter one the corresponging column from the file. And assume errors to the velocities to be $200\\;\\rm{km/s}$ everywhere."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create two arrays\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given an error in distance module, how you would estimate the error in luminosity distance. Think about erros like upper and lower limits."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create an array for errors in luminosity distance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now copy the code you used for the plot and modify it using this [example](http://matplotlib.org/examples/statistics/errorbar_demo_features.html)\n",
      "in order to plot errorbars."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# write a code which plots a figure with errorbars\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fitting\n",
      "-------\n",
      "\n",
      "Now we have a nice plot with errorbars. Such a figure is much more informative. It allows one to use a fitting method. Check a tutorials online, if you are not familiar with these technics. For example, this [one](http://nbviewer.ipython.org/url/media.usm.maine.edu/~pauln/ScipyScriptRepo/CurveFitting.ipynb). If you know the theory fitting, but do not know how to do it in python, consider to look at the documentation for [leastsq](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.leastsq.html#scipy.optimize.leastsq) function and example of its usage [here](http://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#least-square-fitting-leastsq).\n",
      "\n",
      "Taking into account the errors from both axes might be too complicated, so try to start only with errors in distance moduli."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The essential part of any statistical analysis is to produce not only some value, but also a confidence interval for it. When we were estimating the value of $\\Omega_m$ in the lesson, we found it to be around $0.3$. What did you find? What is the error?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Type you result here\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}