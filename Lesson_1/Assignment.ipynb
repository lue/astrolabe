{
 "metadata": {
  "name": "",
  "signature": "sha256:4d284a31a0ed9cf7038a2ab703067717696920fe6905e0d524dc0e8dd16ebae0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assignment #1\n",
      "=============\n",
      "\n",
      "The objective of this assignment is to continue the analysis we have started doing in the lesson. If in the lesson the source code was already provided and you only ran it, now you are supposed to write it by yourself. However, steps you need to take are outlined and web links to various tutorials and library documentations are given for your own investigation.\n",
      "\n",
      "Uncertainties of measurements\n",
      "-----------------------------\n",
      "\n",
      "The uncertanity consists of two components. The first is the measurment error and the second is intrinsic scatter. For instance, imagine an experiment where you measure the length of carrots with a ruller.\n",
      "\n",
      "Your ruller has some precision, say $0.1,\\rm{cm}$, in this case your measurment error will be $0.05,\\rm{cm}$. So the measurment of each carrot has an error $0.05,\\rm{cm}$. But the carrots have different length, therefore you have another source of uncertanity.\n",
      "\n",
      "We have two dimensional data. The magnitude of the source (expressed as distance moduli) and the redshift. \n",
      "\n",
      "Firstly, let's figure out what is error in redshift. \n",
      "\n",
      "The specral analysis is able to extract the redshift of the source with very high precision. Therefore the errors in redshift are not given in the tables. However, the redshift we measure reveals only relative velocity to us, the observer. This velocity includes not only Hubble expansion, but also peculiar velocity of the source. This velocity can be estimated as a few hundreds of $\\rm{km/s}$ ($200-300$). Therefore, this factor dominates and only its contribution to the unceratnity is considered.\n",
      "\n",
      "Secondly, the distance moduli. Situation is opposite to what we have with redshift. Here the error in measurment dominates the intrinsic scatter. Mostly because we do not have much information about explosions.\n",
      "\n",
      "Thats said, now you should try to make a plot we have already done in the lesson but including the errors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import all necessary modules\n",
      "\n",
      "\n",
      "# and press Shift+Enter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# download and read the data (also convert redshifts to velocities)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make the same plot we had in the lesson\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we want to plot the errorbars on top of it. Let's do some preparations. Create two arrays, which will corresponds to the errors in velocities and distance moduli. Assign to the latter one the corresponging column from the file. And assume errors to the velocities to be $200\\;\\rm{km/s}$ everywhere."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create two arrays\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given an error in distance module, how you would estimate the error in luminosity distance. Think about erros like upper and lower limits."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create an array for errors in luminosity distance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now copy the code you used for the plot and modify it using this [example](http://matplotlib.org/examples/statistics/errorbar_demo_features.html)\n",
      "in order to plot errorbars."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# write a code which plots a figure with errorbars\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fitting\n",
      "-------\n",
      "\n",
      "Now we have a nice plot with errorbars. Such a figure is much more informative. It allows one to use a fitting method. Check a tutorials online, if you are not familiar with these technics. For example, this [one](http://nbviewer.ipython.org/url/media.usm.maine.edu/~pauln/ScipyScriptRepo/CurveFitting.ipynb). If you know the theory fitting, but do not know how to do it in python, consider to look at the documentation for [leastsq](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.leastsq.html#scipy.optimize.leastsq) function and example of its usage [here](http://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#least-square-fitting-leastsq).\n",
      "\n",
      "Taking into account the errors from both axes might be too complicated, so try to start only with errors in distance moduli."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The essential part of any statistical analysis is to produce not only some value, but also a confidence interval for it. When we were estimating the value of $\\Omega_m$ in the lesson, we found it to be around $0.3$. What did you find? What is the error?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Type you result here\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}